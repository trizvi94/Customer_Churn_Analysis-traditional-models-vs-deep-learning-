{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eb01b71-b43f-4e81-921e-ead2b95525ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric Features are ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']\n",
      "Categorical Features are ['Geography', 'Gender']\n",
      "The size of the training set is 8000\n",
      "The size of the test set is 2000\n",
      "Shape of X_train after encoding and scaling: (8000, 11)\n",
      "Shape of X_test after encoding and scaling: (2000, 11)\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score, accuracy_score, fbeta_score, roc_auc_score, roc_curve\n",
    "# from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from imblearn.combine import SMOTEENN\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# # Load the dataset\n",
    "# customer_df = pd.read_csv('./Churn_Modelling.csv')\n",
    "\n",
    "# # Drop unnecessary columns\n",
    "# customer_df = customer_df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "\n",
    "# # Define categorical and numeric features\n",
    "# categorical_features = ['Geography', 'Gender']\n",
    "# numeric_features = ['CreditScore', 'Age', 'Tenure', 'Balance',\n",
    "#                     'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']\n",
    "\n",
    "# print(\"Numeric Features are\", numeric_features)\n",
    "# print(\"Categorical Features are\", categorical_features)\n",
    "\n",
    "# # Split the dataset into training and testing sets\n",
    "# X = customer_df.drop('Exited', axis=1)\n",
    "# y = customer_df['Exited']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# print(\"The size of the training set is\", len(X_train))\n",
    "# print(\"The size of the test set is\", len(X_test))\n",
    "\n",
    "# # Function to scale numeric features\n",
    "# def standard_scaler(df, col_names):\n",
    "#     features = df[col_names]\n",
    "#     scaler = StandardScaler().fit(features.values)\n",
    "#     features = scaler.transform(features.values)\n",
    "#     df[col_names] = features\n",
    "#     return df\n",
    "\n",
    "# # Apply scaling to the numeric features in the training and test sets\n",
    "# X_train = standard_scaler(X_train, numeric_features)\n",
    "# X_test = standard_scaler(X_test, numeric_features)\n",
    "\n",
    "# # Function to perform one-hot encoding on categorical features\n",
    "# def one_hot_encode(df, col_names):\n",
    "#     df_encoded = pd.get_dummies(df, columns=col_names, drop_first=True, dtype='float64')\n",
    "#     return df_encoded\n",
    "\n",
    "# # Apply one-hot encoding to the categorical features in the training and test sets\n",
    "# X_train = one_hot_encode(X_train, categorical_features)\n",
    "# X_test = one_hot_encode(X_test, categorical_features)\n",
    "\n",
    "# # Verify the shapes of the transformed data\n",
    "# print(\"Shape of X_train after encoding and scaling:\", X_train.shape)\n",
    "# print(\"Shape of X_test after encoding and scaling:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "092f29a3-d6ab-4534-b967-c69a131841f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.pipeline import Pipeline, make_pipeline\n",
    "# # Set up cross-validation\n",
    "# kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# # Create the pipeline with SMOTEENN and RandomForestClassifier\n",
    "# smoteenn_pipeline = make_pipeline(SMOTEENN(random_state=42), \n",
    "#                                   RandomForestClassifier(random_state=13))\n",
    "\n",
    "# # Define parameter grid for GridSearchCV\n",
    "# params = {\n",
    "#     'randomforestclassifier__n_estimators': [50, 100, 200],\n",
    "#     'randomforestclassifier__max_depth': [None, 10, 20, 30],\n",
    "# }\n",
    "\n",
    "# # Create a GridSearchCV instance\n",
    "# smoteenn_rf = GridSearchCV(smoteenn_pipeline, param_grid=params, cv=kf, scoring='recall', return_train_score=True)\n",
    "# smoteenn_rf.fit(X_train, y_train)\n",
    "\n",
    "# # Print the best parameters and best score\n",
    "# print('Best parameters:', smoteenn_rf.best_params_)\n",
    "# print('Best score:', smoteenn_rf.best_score_)\n",
    "\n",
    "# # Predict on the test set\n",
    "# y_pred = smoteenn_rf.best_estimator_.named_steps['randomforestclassifier'].predict(X_test)\n",
    "\n",
    "# # Calculate the confusion matrix\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# # Calculate various performance metrics\n",
    "# smoteenn_rf_recall = recall_score(y_test, y_pred)\n",
    "# smoteenn_rf_precision = precision_score(y_test, y_pred)\n",
    "# smoteenn_rf_f1 = f1_score(y_test, y_pred)\n",
    "# smoteenn_rf_f2 = fbeta_score(y_test, y_pred, beta=2)  # Calculate the F2-score\n",
    "# smoteenn_rf_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# # Print the confusion matrix\n",
    "# print(cm)\n",
    "\n",
    "# # Create a DataFrame to store the scores\n",
    "# ndf = [(smoteenn_rf_recall, smoteenn_rf_precision, smoteenn_rf_f1, smoteenn_rf_f2, smoteenn_rf_accuracy)]\n",
    "# smoteenn_rf_score = pd.DataFrame(data=ndf, columns=['Recall', 'Precision', 'F1 Score', 'F2 Score', 'Accuracy'])\n",
    "# smoteenn_rf_score.insert(0, 'Random Forest with', 'SMOTEENN')\n",
    "\n",
    "# # Display the DataFrame with the scores\n",
    "# print(smoteenn_rf_score)\n",
    "\n",
    "# # Calculate AUC-ROC score\n",
    "# y_pred_proba = smoteenn_rf.best_estimator_.named_steps['randomforestclassifier'].predict_proba(X_test)[:, 1]\n",
    "# smoteenn_rf_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# # Print AUC-ROC score\n",
    "# print('AUC-ROC Score:', smoteenn_rf_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7119db56-d6e1-44f7-ab34-98b54745827a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest with</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>0.77887</td>\n",
       "      <td>0.449008</td>\n",
       "      <td>0.569632</td>\n",
       "      <td>0.679092</td>\n",
       "      <td>0.7605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Random Forest with   Recall  Precision  F1 Score  F2 Score  Accuracy\n",
       "0           SMOTEENN  0.77887   0.449008  0.569632  0.679092    0.7605"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoteenn_rf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ccebd1-9dff-4f2d-8a96-010535a0de97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d86f5d7-9520-4563-8cb2-cbec75b6ba2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for SVM with Class Weights:\n",
      "[[1275  318]\n",
      " [ 104  303]]\n",
      "Confusion Matrix for SVM with SMOTE + Tomek Links:\n",
      "[[1296  297]\n",
      " [ 117  290]]\n",
      "Confusion Matrix for SVM with SMOTE Oversampling:\n",
      "[[1297  296]\n",
      " [ 117  290]]\n",
      "Confusion Matrix for SVM with Random Oversampling:\n",
      "[[1278  315]\n",
      " [ 105  302]]\n",
      "Confusion Matrix for SVM with SMOTEENN:\n",
      "[[1156  437]\n",
      " [  85  322]]\n",
      "Confusion Matrix for SVM with No Sampling:\n",
      "[[1563   30]\n",
      " [ 242  165]]\n",
      "                          Model    Recall  Precision  F1 Score  F2 Score  \\\n",
      "0        SVM with Class Weights  0.744472   0.487923  0.589494  0.673633   \n",
      "1  SVM with SMOTE + Tomek Links  0.712531   0.494037  0.583501  0.654628   \n",
      "2   SVM with SMOTE Oversampling  0.712531   0.494881  0.584089  0.654923   \n",
      "3  SVM with Random Oversampling  0.742015   0.489465  0.589844  0.672606   \n",
      "4             SVM with SMOTEENN  0.791155   0.424242  0.552316  0.674487   \n",
      "5          SVM with No Sampling  0.405405   0.846154  0.548173  0.452551   \n",
      "\n",
      "   Accuracy   AUC-ROC  \n",
      "0    0.7890  0.854520  \n",
      "1    0.7930  0.837114  \n",
      "2    0.7935  0.836923  \n",
      "3    0.7900  0.852574  \n",
      "4    0.7390  0.838472  \n",
      "5    0.8640  0.824076  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score, accuracy_score, fbeta_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "customer_df = pd.read_csv('./Churn_Modelling.csv')\n",
    "customer_df = customer_df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "\n",
    "# Define features and target\n",
    "X = customer_df.drop('Exited', axis=1)\n",
    "y = customer_df['Exited']\n",
    "\n",
    "# Define numeric and categorical features\n",
    "numeric_features = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']\n",
    "categorical_features = ['Geography', 'Gender']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize numeric features\n",
    "def standard_scaler(df, col_names):\n",
    "    scaler = StandardScaler().fit(df[col_names])\n",
    "    df[col_names] = scaler.transform(df[col_names])\n",
    "    return df\n",
    "\n",
    "X_train = standard_scaler(X_train, numeric_features)\n",
    "X_test = standard_scaler(X_test, numeric_features)\n",
    "\n",
    "# One-hot encode categorical features\n",
    "def one_hot_encode(df, col_names):\n",
    "    df_encoded = pd.get_dummies(df, columns=col_names, drop_first=True)\n",
    "    return df_encoded\n",
    "\n",
    "X_train = one_hot_encode(X_train, categorical_features)\n",
    "X_test = one_hot_encode(X_test, categorical_features)\n",
    "\n",
    "# Define function to calculate metrics\n",
    "def calculate_metrics(y_test, y_pred, y_pred_proba, model_name):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    f2 = fbeta_score(y_test, y_pred, beta=2)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    print(f\"Confusion Matrix for {model_name}:\")\n",
    "    print(cm)\n",
    "\n",
    "    return [model_name, recall, precision, f1, f2, accuracy, auc_roc]\n",
    "\n",
    "# List to hold all results\n",
    "results = []\n",
    "\n",
    "# 1. SVM with Class Weights\n",
    "class_weights_svm = SVC(class_weight='balanced', probability=True, random_state=42)\n",
    "class_weights_svm.fit(X_train, y_train)\n",
    "class_weights_y_pred = class_weights_svm.predict(X_test)\n",
    "class_weights_y_pred_proba = class_weights_svm.predict_proba(X_test)[:, 1]\n",
    "results.append(calculate_metrics(y_test, class_weights_y_pred, class_weights_y_pred_proba, 'SVM with Class Weights'))\n",
    "\n",
    "# 2. SVM with SMOTE + Tomek Links\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "X_resampled, y_resampled = smote_tomek.fit_resample(X_train, y_train)\n",
    "smote_tomek_svm = SVC(probability=True, random_state=42)\n",
    "smote_tomek_svm.fit(X_resampled, y_resampled)\n",
    "smote_tomek_y_pred = smote_tomek_svm.predict(X_test)\n",
    "smote_tomek_y_pred_proba = smote_tomek_svm.predict_proba(X_test)[:, 1]\n",
    "results.append(calculate_metrics(y_test, smote_tomek_y_pred, smote_tomek_y_pred_proba, 'SVM with SMOTE + Tomek Links'))\n",
    "\n",
    "# 3. SVM with SMOTE Oversampling\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "smote_svm = SVC(probability=True, random_state=42)\n",
    "smote_svm.fit(X_resampled, y_resampled)\n",
    "smote_y_pred = smote_svm.predict(X_test)\n",
    "smote_y_pred_proba = smote_svm.predict_proba(X_test)[:, 1]\n",
    "results.append(calculate_metrics(y_test, smote_y_pred, smote_y_pred_proba, 'SVM with SMOTE Oversampling'))\n",
    "\n",
    "# 4. SVM with Random Oversampling\n",
    "random_over = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = random_over.fit_resample(X_train, y_train)\n",
    "random_over_svm = SVC(probability=True, random_state=42)\n",
    "random_over_svm.fit(X_resampled, y_resampled)\n",
    "random_over_y_pred = random_over_svm.predict(X_test)\n",
    "random_over_y_pred_proba = random_over_svm.predict_proba(X_test)[:, 1]\n",
    "results.append(calculate_metrics(y_test, random_over_y_pred, random_over_y_pred_proba, 'SVM with Random Oversampling'))\n",
    "\n",
    "# 5. SVM with SMOTEENN\n",
    "smoteenn = SMOTEENN(random_state=42)\n",
    "X_resampled, y_resampled = smoteenn.fit_resample(X_train, y_train)\n",
    "smoteenn_svm = SVC(probability=True, random_state=42)\n",
    "smoteenn_svm.fit(X_resampled, y_resampled)\n",
    "smoteenn_y_pred = smoteenn_svm.predict(X_test)\n",
    "smoteenn_y_pred_proba = smoteenn_svm.predict_proba(X_test)[:, 1]\n",
    "results.append(calculate_metrics(y_test, smoteenn_y_pred, smoteenn_y_pred_proba, 'SVM with SMOTEENN'))\n",
    "\n",
    "# 6. SVM with No Sampling\n",
    "no_sampling_svm = SVC(probability=True, random_state=42)\n",
    "no_sampling_svm.fit(X_train, y_train)\n",
    "no_sampling_y_pred = no_sampling_svm.predict(X_test)\n",
    "no_sampling_y_pred_proba = no_sampling_svm.predict_proba(X_test)[:, 1]\n",
    "results.append(calculate_metrics(y_test, no_sampling_y_pred, no_sampling_y_pred_proba, 'SVM with No Sampling'))\n",
    "\n",
    "# Create a DataFrame with all results\n",
    "columns = ['Model', 'Recall', 'Precision', 'F1 Score', 'F2 Score', 'Accuracy', 'AUC-ROC']\n",
    "results_df = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa7a462b-16e3-4077-afb4-94236e71a603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC-ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM with Class Weights</td>\n",
       "      <td>0.744472</td>\n",
       "      <td>0.487923</td>\n",
       "      <td>0.589494</td>\n",
       "      <td>0.673633</td>\n",
       "      <td>0.7890</td>\n",
       "      <td>0.854520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM with SMOTE + Tomek Links</td>\n",
       "      <td>0.712531</td>\n",
       "      <td>0.494037</td>\n",
       "      <td>0.583501</td>\n",
       "      <td>0.654628</td>\n",
       "      <td>0.7930</td>\n",
       "      <td>0.837114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM with SMOTE Oversampling</td>\n",
       "      <td>0.712531</td>\n",
       "      <td>0.494881</td>\n",
       "      <td>0.584089</td>\n",
       "      <td>0.654923</td>\n",
       "      <td>0.7935</td>\n",
       "      <td>0.836923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM with Random Oversampling</td>\n",
       "      <td>0.742015</td>\n",
       "      <td>0.489465</td>\n",
       "      <td>0.589844</td>\n",
       "      <td>0.672606</td>\n",
       "      <td>0.7900</td>\n",
       "      <td>0.852574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM with SMOTEENN</td>\n",
       "      <td>0.791155</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.552316</td>\n",
       "      <td>0.674487</td>\n",
       "      <td>0.7390</td>\n",
       "      <td>0.838472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM with No Sampling</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.548173</td>\n",
       "      <td>0.452551</td>\n",
       "      <td>0.8640</td>\n",
       "      <td>0.824076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model    Recall  Precision  F1 Score  F2 Score  \\\n",
       "0        SVM with Class Weights  0.744472   0.487923  0.589494  0.673633   \n",
       "1  SVM with SMOTE + Tomek Links  0.712531   0.494037  0.583501  0.654628   \n",
       "2   SVM with SMOTE Oversampling  0.712531   0.494881  0.584089  0.654923   \n",
       "3  SVM with Random Oversampling  0.742015   0.489465  0.589844  0.672606   \n",
       "4             SVM with SMOTEENN  0.791155   0.424242  0.552316  0.674487   \n",
       "5          SVM with No Sampling  0.405405   0.846154  0.548173  0.452551   \n",
       "\n",
       "   Accuracy   AUC-ROC  \n",
       "0    0.7890  0.854520  \n",
       "1    0.7930  0.837114  \n",
       "2    0.7935  0.836923  \n",
       "3    0.7900  0.852574  \n",
       "4    0.7390  0.838472  \n",
       "5    0.8640  0.824076  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbcce56-9e64-43e2-ab1d-d0b1a6885dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55427d0c-81a6-4ec1-bd0f-4c3dc78d3205",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283435fc-6d42-4cd6-b654-6b2976c001cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score, accuracy_score, fbeta_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "customer_df = pd.read_csv('./Churn_Modelling.csv')\n",
    "customer_df = customer_df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "\n",
    "# Define features and target\n",
    "X = customer_df.drop('Exited', axis=1)\n",
    "y = customer_df['Exited']\n",
    "\n",
    "# Define numeric and categorical features\n",
    "numeric_features = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']\n",
    "categorical_features = ['Geography', 'Gender']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize numeric features\n",
    "def standard_scaler(df, col_names):\n",
    "    scaler = StandardScaler().fit(df[col_names])\n",
    "    df[col_names] = scaler.transform(df[col_names])\n",
    "    return df\n",
    "\n",
    "X_train = standard_scaler(X_train, numeric_features)\n",
    "X_test = standard_scaler(X_test, numeric_features)\n",
    "\n",
    "# One-hot encode categorical features\n",
    "def one_hot_encode(df, col_names):\n",
    "    df_encoded = pd.get_dummies(df, columns=col_names, drop_first=True)\n",
    "    return df_encoded\n",
    "\n",
    "X_train = one_hot_encode(X_train, categorical_features)\n",
    "X_test = one_hot_encode(X_test, categorical_features)\n",
    "\n",
    "# Define function to calculate metrics\n",
    "def calculate_metrics(y_test, y_pred, y_pred_proba, model_name):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    f2 = fbeta_score(y_test, y_pred, beta=2)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    print(f\"Confusion Matrix for {model_name}:\")\n",
    "    print(cm)\n",
    "\n",
    "    return [model_name, recall, precision, f1, f2, accuracy, auc_roc]\n",
    "\n",
    "# List to hold all results\n",
    "results = []\n",
    "\n",
    "# Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'svc__C': [0.1, 1, 10, 100],\n",
    "    'svc__kernel': ['linear', 'rbf', 'poly'],\n",
    "    'svc__gamma': ['scale', 'auto'],\n",
    "    'svc__degree': [3, 4, 5],  # Only relevant for 'poly' kernel\n",
    "    'svc__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "def perform_grid_search(X_train, y_train, model_name, pipeline):\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='recall', n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "    print(f'Best parameters for {model_name}: {best_params}')\n",
    "    print(f'Best recall score for {model_name}: {best_score}')\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "    y_pred_proba = grid_search.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    return calculate_metrics(y_test, y_pred, y_pred_proba, model_name)\n",
    "\n",
    "# 1. SVM with Class Weights\n",
    "pipeline_class_weights = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svc', SVC(class_weight='balanced', probability=True, random_state=42))\n",
    "])\n",
    "results.append(perform_grid_search(X_train, y_train, 'SVM with Class Weights', pipeline_class_weights))\n",
    "\n",
    "# 2. SVM with SMOTE + Tomek Links\n",
    "pipeline_smote_tomek = Pipeline(steps=[\n",
    "    ('smote_tomek', SMOTETomek(random_state=42)),\n",
    "    ('svc', SVC(probability=True, random_state=42))\n",
    "])\n",
    "results.append(perform_grid_search(X_train, y_train, 'SVM with SMOTE + Tomek Links', pipeline_smote_tomek))\n",
    "\n",
    "# 3. SVM with SMOTE Oversampling\n",
    "pipeline_smote = Pipeline(steps=[\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('svc', SVC(probability=True, random_state=42))\n",
    "])\n",
    "results.append(perform_grid_search(X_train, y_train, 'SVM with SMOTE Oversampling', pipeline_smote))\n",
    "\n",
    "# 4. SVM with Random Oversampling\n",
    "pipeline_random_over = Pipeline(steps=[\n",
    "    ('random_over', RandomOverSampler(random_state=42)),\n",
    "    ('svc', SVC(probability=True, random_state=42))\n",
    "])\n",
    "results.append(perform_grid_search(X_train, y_train, 'SVM with Random Oversampling', pipeline_random_over))\n",
    "\n",
    "# 5. SVM with SMOTEENN\n",
    "pipeline_smoteenn = Pipeline(steps=[\n",
    "    ('smoteenn', SMOTEENN(random_state=42)),\n",
    "    ('svc', SVC(probability=True, random_state=42))\n",
    "])\n",
    "results.append(perform_grid_search(X_train, y_train, 'SVM with SMOTEENN', pipeline_smoteenn))\n",
    "\n",
    "# 6. SVM with No Sampling\n",
    "pipeline_no_sampling = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svc', SVC(probability=True, random_state=42))\n",
    "])\n",
    "results.append(perform_grid_search(X_train, y_train, 'SVM with No Sampling', pipeline_no_sampling))\n",
    "\n",
    "# Create a DataFrame with all results\n",
    "columns = ['Model', 'Recall', 'Precision', 'F1 Score', 'F2 Score', 'Accuracy', 'AUC-ROC']\n",
    "results_df = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d3719f-62de-4bec-baf9-da568ce6034c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0e1f3d-957b-4279-9a52-36ae70a265db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388e31fc-4731-4593-a0b3-34751c1aeb5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25652cbf-7eba-4779-9b4a-fc70495b7812",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
