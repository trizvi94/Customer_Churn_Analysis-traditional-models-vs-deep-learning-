{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "19cdfcfd-755c-4576-803a-c1a96edd06a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "78945d1a-43f3-4fd5-95f3-f6db71bd0db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "def set_seeds(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "201a1027-6e8c-48c8-a301-06a0dd9da4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df = pd.read_csv('./Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5fbe7b83-4389-48f1-9d0e-08ed856f8107",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df= customer_df.drop('RowNumber', axis=1)\n",
    "customer_df= customer_df.drop('CustomerId', axis=1)\n",
    "customer_df= customer_df.drop('Surname', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "798afbc3-4e23-494f-a246-4d9a7420eb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeac8bd-b3fc-40f7-aeb9-276cecfd1db8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e1d2f06b-474e-494f-8b09-b12df358069a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cbb9a4f8-f404-4fca-9552-541d2faa10df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = customer_df.drop('Exited', axis=1)\n",
    "y = customer_df['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a9cdeeb5-9219-450e-94f8-f037d7eb791b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric Features are ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']\n",
      "Categorical Features are ['Geography', 'Gender']\n"
     ]
    }
   ],
   "source": [
    "categorical_features = ['Geography', 'Gender']\n",
    "# numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "numeric_features=['CreditScore', 'Age', 'Tenure', 'Balance',\n",
    "       'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']\n",
    "print(\"Numeric Features are\", numeric_features)\n",
    "print(\"Categorical Features are\", categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "24ae0e2a-d075-4eca-987d-a65dab8a0aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "22b0a7d2-6113-4f64-a402-3c7c02695f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Creating function for scaling\n",
    "def Standard_Scaler (df, col_names):\n",
    "    features = df[col_names]\n",
    "    scaler = StandardScaler().fit(features.values)\n",
    "    features = scaler.transform(features.values)\n",
    "    df[col_names] = features\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c3aef40a-f72b-4bb3-b4d3-9505bc1b0a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = numeric_features\n",
    "X_train = Standard_Scaler (X_train, col_names)\n",
    "X_test = Standard_Scaler (X_test, col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5f666e27-91b9-492b-a0af-8c302838f762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df, col_names):\n",
    "    \"\"\"\n",
    "    Perform one-hot encoding on specified categorical columns of a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame containing the categorical columns.\n",
    "    col_names (list of str): List of column names to one-hot encode.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The DataFrame with one-hot encoded columns.\n",
    "    \"\"\"\n",
    "    # Perform one-hot encoding on the specified columns\n",
    "    df_encoded = pd.get_dummies(df, columns=col_names, drop_first=True, dtype='float64')\n",
    "\n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "63e4b657-e4dd-425c-9a3b-79e01f345c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = categorical_features\n",
    "X_train = one_hot_encode (X_train, col_names)\n",
    "X_test = one_hot_encode (X_test, col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b39937a9-099a-4db3-8db8-1d3075d14a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
       "       'IsActiveMember', 'EstimatedSalary', 'Geography_Germany',\n",
       "       'Geography_Spain', 'Gender_Male'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "923dc9f4-586f-4707-ac93-b389e7aaaeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, recall_score, roc_auc_score\n",
    "\n",
    "# # Assuming y_train and y_test are in integer format (0 or 1 for binary classification)\n",
    "# # Convert y_train and y_test to one-hot encoding\n",
    "# y_train_categorical = to_categorical(y_train)\n",
    "# y_test_categorical = to_categorical(y_test)\n",
    "\n",
    "# Reshape data for CNN\n",
    "X_train_reshaped = X_train.values.reshape(-1, X_train.shape[1], 1)\n",
    "X_test_reshaped = X_test.values.reshape(-1, X_test.shape[1], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "66650121-779d-4f62-a366-38cce860d453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model(model1)\n",
    "def build_cnn(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(2, activation='softmax')  # Assuming binary classification\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a2e1006e-8a02-4aaf-aab6-d9eb7d96961a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "200/200 [==============================] - 3s 7ms/step - loss: 0.6892 - accuracy: 0.7623 - val_loss: 2.2478 - val_accuracy: 0.2019\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.4378 - accuracy: 0.8116 - val_loss: 0.4013 - val_accuracy: 0.8419\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.4162 - accuracy: 0.8198 - val_loss: 0.3674 - val_accuracy: 0.8675\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.4084 - accuracy: 0.8258 - val_loss: 0.3487 - val_accuracy: 0.8694\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.3956 - accuracy: 0.8336 - val_loss: 0.3386 - val_accuracy: 0.8656\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.3949 - accuracy: 0.8356 - val_loss: 0.3339 - val_accuracy: 0.8712\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.3809 - accuracy: 0.8441 - val_loss: 0.3340 - val_accuracy: 0.8700\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.3868 - accuracy: 0.8403 - val_loss: 0.3344 - val_accuracy: 0.8644\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.3800 - accuracy: 0.8439 - val_loss: 0.3337 - val_accuracy: 0.8656\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.3791 - accuracy: 0.8408 - val_loss: 0.3409 - val_accuracy: 0.8650\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.3747 - accuracy: 0.8467 - val_loss: 0.3326 - val_accuracy: 0.8669\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.3772 - accuracy: 0.8467 - val_loss: 0.3273 - val_accuracy: 0.8681\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.3763 - accuracy: 0.8452 - val_loss: 0.3330 - val_accuracy: 0.8650\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.3714 - accuracy: 0.8475 - val_loss: 0.3280 - val_accuracy: 0.8694\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.3697 - accuracy: 0.8492 - val_loss: 0.3299 - val_accuracy: 0.8669\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.3610 - accuracy: 0.8525 - val_loss: 0.3281 - val_accuracy: 0.8687\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 2s 10ms/step - loss: 0.3687 - accuracy: 0.8467 - val_loss: 0.3263 - val_accuracy: 0.8719\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.3659 - accuracy: 0.8508 - val_loss: 0.3346 - val_accuracy: 0.8681\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.3648 - accuracy: 0.8477 - val_loss: 0.3270 - val_accuracy: 0.8706\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.3589 - accuracy: 0.8483 - val_loss: 0.3262 - val_accuracy: 0.8712\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.3637 - accuracy: 0.8519 - val_loss: 0.3277 - val_accuracy: 0.8669\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.3629 - accuracy: 0.8523 - val_loss: 0.3268 - val_accuracy: 0.8669\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.3594 - accuracy: 0.8537 - val_loss: 0.3279 - val_accuracy: 0.8712\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.3612 - accuracy: 0.8525 - val_loss: 0.3342 - val_accuracy: 0.8675\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.3585 - accuracy: 0.8525 - val_loss: 0.3286 - val_accuracy: 0.8725\n",
      "63/63 [==============================] - 1s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# Build and train the CNN model\n",
    "cnn_model = build_cnn((X_train_reshaped.shape[1], 1))\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# Train the model\n",
    "history_cnn = cnn_model.fit(\n",
    "    X_train_reshaped, y_train_categorical,\n",
    "    epochs=50,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping],\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "cnn_predictions = cnn_model.predict(X_test_reshaped)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "cnn_pred_labels = np.argmax(cnn_predictions, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "459c45b7-cc13-4b31-b78d-8d2832a400ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC-ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN with no Under/Over Sampling</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0.763265</td>\n",
       "      <td>0.57362</td>\n",
       "      <td>0.499199</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.849831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model    Recall  Precision  F1 Score  F2 Score  \\\n",
       "0  CNN with no Under/Over Sampling  0.459459   0.763265   0.57362  0.499199   \n",
       "\n",
       "   Accuracy   AUC-ROC  \n",
       "0     0.861  0.849831  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, fbeta_score, accuracy_score, roc_auc_score\n",
    "\n",
    "# Calculate performance metrics\n",
    "recall = recall_score(y_test, cnn_pred_labels)\n",
    "precision = precision_score(y_test, cnn_pred_labels)\n",
    "f1 = f1_score(y_test, cnn_pred_labels)\n",
    "f2 = fbeta_score(y_test, cnn_pred_labels, beta=2)\n",
    "accuracy = accuracy_score(y_test, cnn_pred_labels)\n",
    "roc_auc = roc_auc_score(y_test, cnn_predictions[:, 1])\n",
    "\n",
    "# Create a list to store the metrics\n",
    "metrics = [(recall, precision, f1, f2, accuracy,roc_auc)]\n",
    "\n",
    "# Create a DataFrame to store the scores\n",
    "cnn_score = pd.DataFrame(data=metrics, columns=['Recall', 'Precision', 'F1 Score', 'F2 Score', 'Accuracy', 'AUC-ROC'])\n",
    "\n",
    "# Insert a column for the model name\n",
    "cnn_score.insert(0, 'Model', 'CNN with no Under/Over Sampling')\n",
    "\n",
    "# Display the DataFrame\n",
    "cnn_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec34ea65-8a3c-40cd-8565-df866f61b22b",
   "metadata": {},
   "source": [
    "## using Class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b23f65e-7ba8-4dca-a3f1-e9b57866093b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5321a2c8-179c-48cd-ab8d-7a93e3026cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62638f12-5c33-4f6b-ab4f-8936a54af8a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c02cfa0-8f80-491d-945e-c55b0d76c9c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63867a5-e3a4-4b57-a60d-cc84d26e1ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe14e9a-e584-4087-87d1-6a28116ed18b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26b9eea-37a9-41a5-97c1-880ed319484f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4083fa0-9028-402d-90b0-e841b9f8811d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a96dbdc-88f4-4bd9-9718-dd00e489db1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c2435147-7e66-4521-9696-98537fdac05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: 0.6279434850863422, 1: 2.4539877300613497}\n",
      "Epoch 1/50\n",
      "200/200 [==============================] - 8s 30ms/step - loss: 1.0125 - accuracy: 0.5958 - val_loss: 1.0143 - val_accuracy: 0.2412\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.6413 - accuracy: 0.6636 - val_loss: 0.5250 - val_accuracy: 0.7456\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.5909 - accuracy: 0.6964 - val_loss: 0.5236 - val_accuracy: 0.7794\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.5669 - accuracy: 0.7114 - val_loss: 0.5014 - val_accuracy: 0.7975\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5441 - accuracy: 0.7328 - val_loss: 0.4798 - val_accuracy: 0.8125\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.5319 - accuracy: 0.7473 - val_loss: 0.4449 - val_accuracy: 0.8163\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.5308 - accuracy: 0.7425 - val_loss: 0.4803 - val_accuracy: 0.8188\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.5130 - accuracy: 0.7634 - val_loss: 0.4633 - val_accuracy: 0.8075\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.5153 - accuracy: 0.7692 - val_loss: 0.5064 - val_accuracy: 0.7906\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.5016 - accuracy: 0.7763 - val_loss: 0.4703 - val_accuracy: 0.8306\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.5028 - accuracy: 0.7759 - val_loss: 0.4055 - val_accuracy: 0.8381\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.5017 - accuracy: 0.7700 - val_loss: 0.4476 - val_accuracy: 0.8356\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.5038 - accuracy: 0.7773 - val_loss: 0.4666 - val_accuracy: 0.8062\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.4952 - accuracy: 0.7731 - val_loss: 0.4747 - val_accuracy: 0.8244\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 0.4992 - accuracy: 0.7706 - val_loss: 0.4782 - val_accuracy: 0.7994\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.4960 - accuracy: 0.7789 - val_loss: 0.4697 - val_accuracy: 0.8044\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score, accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming y_train contains the class labels\n",
    "class_weights_array = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "\n",
    "# Convert to dictionary format\n",
    "class_weights_dict = dict(enumerate(class_weights_array))\n",
    "print(\"Class Weights:\", class_weights_dict)\n",
    "\n",
    "\n",
    "def build_cnn_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=256, kernel_size=5, activation='relu', padding='same', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Conv1D(filters=256, kernel_size=5, activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.5),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(2, activation='softmax')  # Adjust for the number of classes\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define input shape\n",
    "input_shape_cnn = (X_train_reshaped.shape[1], 1)\n",
    "cnn_model_class_weights = build_cnn_model(input_shape_cnn)\n",
    "\n",
    "# Train the model\n",
    "history_cnn_class_weights = cnn_model_class_weights.fit(\n",
    "    X_train_reshaped,  # Reshaped training data\n",
    "    y_train_categorical,  # One-hot encoded labels\n",
    "    epochs=50,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)],\n",
    "    batch_size=32,\n",
    "    verbose=1,\n",
    "    class_weight=class_weights_dict  # Pass class weights here\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7560f27a-af74-4b4f-94ac-0c6544da06c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000,)\n",
      "(8000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_train_categorical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cda4f600-b680-4319-9702-d64eab791832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 9ms/step\n",
      "Confusion Matrix with Class Weights:\n",
      " [[1384  209]\n",
      " [ 139  268]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC-ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN with Class Weights</td>\n",
       "      <td>0.658477</td>\n",
       "      <td>0.561845</td>\n",
       "      <td>0.606335</td>\n",
       "      <td>0.63658</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.850862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model    Recall  Precision  F1 Score  F2 Score  Accuracy  \\\n",
       "0  CNN with Class Weights  0.658477   0.561845  0.606335   0.63658     0.826   \n",
       "\n",
       "    AUC-ROC  \n",
       "0  0.850862  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import fbeta_score, confusion_matrix, recall_score, precision_score, f1_score, accuracy_score\n",
    "\n",
    "# Make predictions\n",
    "cnn_predictions_class_weights = cnn_model_class_weights.predict(X_test_reshaped)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "cnn_pred_labels_class_weights = np.argmax(cnn_predictions_class_weights, axis=1)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_class_weights = confusion_matrix(y_test, cnn_pred_labels_class_weights)\n",
    "\n",
    "# Calculate metrics\n",
    "cnn_recall_class_weights = recall_score(y_test, cnn_pred_labels_class_weights)\n",
    "cnn_precision_class_weights = precision_score(y_test, cnn_pred_labels_class_weights)\n",
    "cnn_f1_class_weights = f1_score(y_test, cnn_pred_labels_class_weights)\n",
    "cnn_f2_class_weights = fbeta_score(y_test, cnn_pred_labels_class_weights, beta=2)\n",
    "cnn_accuracy_class_weights = accuracy_score(y_test, cnn_pred_labels_class_weights)\n",
    "cnn_roc_auc = roc_auc_score(y_test, cnn_predictions_class_weights[:, 1])\n",
    "\n",
    "# Print Confusion Matrix\n",
    "print(\"Confusion Matrix with Class Weights:\\n\", cm_class_weights)\n",
    "\n",
    "# Create a list to store the metrics\n",
    "metrics_class_weights = [(cnn_recall_class_weights, cnn_precision_class_weights, cnn_f1_class_weights, cnn_f2_class_weights, cnn_accuracy_class_weights,cnn_roc_auc)]\n",
    "\n",
    "# Create a DataFrame to store the scores\n",
    "cnn_score_class_weights = pd.DataFrame(data=metrics_class_weights, columns=['Recall', 'Precision', 'F1 Score', 'F2 Score', 'Accuracy','AUC-ROC'])\n",
    "\n",
    "# Insert a column for the model name\n",
    "cnn_score_class_weights.insert(0, 'Model', 'CNN with Class Weights')\n",
    "\n",
    "# Display the DataFrame\n",
    "cnn_score_class_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44f28d2-86bb-47f9-a3b9-a7e0ebe8d6a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8e0c04-b049-4af3-9d6e-78a89275388a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e1b5a7-bcb8-4f15-8202-c777f439a200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15a9b154-0153-4188-9bef-1406d4d347d0",
   "metadata": {},
   "source": [
    "## Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6d421eb4-5b57-4af1-9073-50786cae5333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of X_train and X_test, and data type:  8000 <class 'pandas.core.series.Series'>\n",
      "Length of Y_train and Y_test, and data type:  2000 <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of X_train and X_test, and data type: \",len(X_train),type(y_train))\n",
    "print(\"Length of Y_train and Y_test, and data type: \",len(X_test),type(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2dea5d-597b-4b83-b2cf-9f07e2497ed2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09683d8b-eced-4a02-9c06-e4eaeaa77028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c228c72f-29d3-45a4-98b2-8d399e48fe2d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c341140-650a-4474-8af0-47fdc92a3332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e4cd2df-4f3b-4520-b29a-89816fd75e2c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93030a92-821a-4abd-86ed-521566f359b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8de841a-c089-4c1f-b9a7-438c1b7844dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3a5c0e06-dde4-423e-a22e-48e2456ea09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "319/319 [==============================] - 3s 5ms/step - loss: 0.5568 - accuracy: 0.7137 - val_loss: 0.6007 - val_accuracy: 0.6829\n",
      "Epoch 2/50\n",
      "319/319 [==============================] - 3s 8ms/step - loss: 0.4887 - accuracy: 0.7601 - val_loss: 0.9509 - val_accuracy: 0.4470\n",
      "Epoch 3/50\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 0.4703 - accuracy: 0.7753 - val_loss: 0.5111 - val_accuracy: 0.7257\n",
      "Epoch 4/50\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 0.4608 - accuracy: 0.7815 - val_loss: 0.5392 - val_accuracy: 0.7139\n",
      "Epoch 5/50\n",
      "319/319 [==============================] - 3s 9ms/step - loss: 0.4540 - accuracy: 0.7881 - val_loss: 0.5135 - val_accuracy: 0.7402\n",
      "Epoch 6/50\n",
      "319/319 [==============================] - 2s 8ms/step - loss: 0.4456 - accuracy: 0.7911 - val_loss: 0.6725 - val_accuracy: 0.6232\n",
      "Epoch 7/50\n",
      "319/319 [==============================] - 1s 4ms/step - loss: 0.4421 - accuracy: 0.7899 - val_loss: 0.7137 - val_accuracy: 0.6075\n",
      "Epoch 8/50\n",
      "319/319 [==============================] - 2s 7ms/step - loss: 0.4367 - accuracy: 0.7968 - val_loss: 0.4864 - val_accuracy: 0.7484\n",
      "Epoch 9/50\n",
      "319/319 [==============================] - 2s 7ms/step - loss: 0.4289 - accuracy: 0.7996 - val_loss: 0.7928 - val_accuracy: 0.5565\n",
      "Epoch 10/50\n",
      "319/319 [==============================] - 1s 4ms/step - loss: 0.4231 - accuracy: 0.8037 - val_loss: 0.5760 - val_accuracy: 0.6852\n",
      "Epoch 11/50\n",
      "319/319 [==============================] - 2s 7ms/step - loss: 0.4204 - accuracy: 0.8052 - val_loss: 0.5064 - val_accuracy: 0.7280\n",
      "Epoch 12/50\n",
      "319/319 [==============================] - 2s 7ms/step - loss: 0.4232 - accuracy: 0.8047 - val_loss: 0.7155 - val_accuracy: 0.6095\n",
      "Epoch 13/50\n",
      "319/319 [==============================] - 1s 4ms/step - loss: 0.4151 - accuracy: 0.8003 - val_loss: 0.4311 - val_accuracy: 0.7975\n",
      "Epoch 14/50\n",
      "319/319 [==============================] - 2s 7ms/step - loss: 0.4107 - accuracy: 0.8087 - val_loss: 0.7937 - val_accuracy: 0.5710\n",
      "Epoch 15/50\n",
      "319/319 [==============================] - 3s 8ms/step - loss: 0.4105 - accuracy: 0.8088 - val_loss: 0.5615 - val_accuracy: 0.6856\n",
      "Epoch 16/50\n",
      "319/319 [==============================] - 3s 8ms/step - loss: 0.4021 - accuracy: 0.8154 - val_loss: 0.6251 - val_accuracy: 0.6762\n",
      "Epoch 17/50\n",
      "319/319 [==============================] - 1s 4ms/step - loss: 0.3993 - accuracy: 0.8130 - val_loss: 0.5704 - val_accuracy: 0.7162\n",
      "Epoch 18/50\n",
      "319/319 [==============================] - 2s 6ms/step - loss: 0.3952 - accuracy: 0.8161 - val_loss: 0.5197 - val_accuracy: 0.7198\n",
      "63/63 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, fbeta_score, accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Convert X_train and X_test to numpy arrays if they're pandas DataFrames\n",
    "X_train_array = X_train.values\n",
    "X_test_array = X_test.values\n",
    "\n",
    "# Apply random oversampling\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train_array, y_train)\n",
    "\n",
    "# Reshape X_train_resampled and X_test for CNN\n",
    "X_train_resampled = X_train_resampled.reshape(X_train_resampled.shape[0], X_train_resampled.shape[1], 1)\n",
    "X_test_reshaped = X_test_array.reshape(X_test_array.shape[0], X_test_array.shape[1], 1)\n",
    "\n",
    "# Convert y_train_resampled and y_test to one-hot encoding\n",
    "y_train_resampled_categorical = to_categorical(y_train_resampled)\n",
    "y_test_categorical = to_categorical(y_test)\n",
    "\n",
    "# Build the CNN model\n",
    "cnn_model_ros = Sequential()\n",
    "\n",
    "cnn_model_ros.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train_resampled.shape[1], 1)))\n",
    "cnn_model_ros.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "cnn_model_ros.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "cnn_model_ros.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "cnn_model_ros.add(Flatten())\n",
    "cnn_model_ros.add(Dense(128, activation='relu'))\n",
    "cnn_model_ros.add(Dropout(0.5))\n",
    "\n",
    "cnn_model_ros.add(Dense(2, activation='softmax'))  # Binary classification\n",
    "\n",
    "# Compile the model\n",
    "cnn_model_ros.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping_ros = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# Train the model\n",
    "history_cnn_ros = cnn_model_ros.fit(\n",
    "    X_train_resampled, y_train_resampled_categorical,\n",
    "    epochs=50,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping_ros],\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "cnn_predictions_ros = cnn_model_ros.predict(X_test_reshaped)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "cnn_pred_labels_ros = np.argmax(cnn_predictions_ros, axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "32368026-f4ed-47bf-bd26-93d9e65292c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC-ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN with Random Oversampling</td>\n",
       "      <td>0.65602</td>\n",
       "      <td>0.553942</td>\n",
       "      <td>0.600675</td>\n",
       "      <td>0.632701</td>\n",
       "      <td>0.8225</td>\n",
       "      <td>0.841277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model   Recall  Precision  F1 Score  F2 Score  \\\n",
       "0  CNN with Random Oversampling  0.65602   0.553942  0.600675  0.632701   \n",
       "\n",
       "   Accuracy   AUC-ROC  \n",
       "0    0.8225  0.841277  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate performance metrics\n",
    "cnn_recall_ros = recall_score(y_test, cnn_pred_labels_ros)\n",
    "cnn_precision_ros = precision_score(y_test, cnn_pred_labels_ros)\n",
    "cnn_f1_ros = f1_score(y_test, cnn_pred_labels_ros)\n",
    "cnn_f2_ros = fbeta_score(y_test, cnn_pred_labels_ros, beta=2)\n",
    "cnn_accuracy_ros = accuracy_score(y_test, cnn_pred_labels_ros)\n",
    "cnn_roc_auc_ros = roc_auc_score(y_test, cnn_predictions_ros[:, 1])\n",
    "\n",
    "\n",
    "# Create a DataFrame to store the scores\n",
    "cnn_score_ros = pd.DataFrame(\n",
    "    data=[(cnn_recall_ros, cnn_precision_ros, cnn_f1_ros, cnn_f2_ros, cnn_accuracy_ros,cnn_roc_auc_ros)],\n",
    "    columns=['Recall', 'Precision', 'F1 Score', 'F2 Score', 'Accuracy','AUC-ROC']\n",
    ")\n",
    "cnn_score_ros.insert(0, 'Model', 'CNN with Random Oversampling')\n",
    "\n",
    "# Display the DataFrame\n",
    "cnn_score_ros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c20f7ad-2ef0-47e8-a65c-e5143de0496a",
   "metadata": {},
   "source": [
    "## SMOTE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6725b0b8-19c6-4c22-8dd5-dd921f30e9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "319/319 [==============================] - 13s 34ms/step - loss: 0.7318 - accuracy: 0.6787 - val_loss: 0.6990 - val_accuracy: 0.6425\n",
      "Epoch 2/50\n",
      "319/319 [==============================] - 10s 33ms/step - loss: 0.5115 - accuracy: 0.7522 - val_loss: 0.5295 - val_accuracy: 0.7225\n",
      "Epoch 3/50\n",
      "319/319 [==============================] - 10s 32ms/step - loss: 0.4876 - accuracy: 0.7686 - val_loss: 0.6007 - val_accuracy: 0.6401\n",
      "Epoch 4/50\n",
      "319/319 [==============================] - 11s 33ms/step - loss: 0.4696 - accuracy: 0.7821 - val_loss: 0.5913 - val_accuracy: 0.6330\n",
      "Epoch 5/50\n",
      "319/319 [==============================] - 10s 32ms/step - loss: 0.4627 - accuracy: 0.7866 - val_loss: 0.5943 - val_accuracy: 0.6162\n",
      "Epoch 6/50\n",
      "319/319 [==============================] - 10s 33ms/step - loss: 0.4529 - accuracy: 0.7902 - val_loss: 0.5343 - val_accuracy: 0.6625\n",
      "Epoch 7/50\n",
      "319/319 [==============================] - 10s 33ms/step - loss: 0.4477 - accuracy: 0.7931 - val_loss: 0.5750 - val_accuracy: 0.6103\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score, accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Convert X_train to numpy array if it's a DataFrame\n",
    "X_train_array = X_train.values\n",
    "y_train_array = y_train.values\n",
    "\n",
    "# Apply SMOTE oversampling\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_array, y_train_array)\n",
    "\n",
    "# Reshape X_train_resampled for CNN\n",
    "X_train_resampled = X_train_resampled.reshape(X_train_resampled.shape[0], X_train_resampled.shape[1], 1)\n",
    "\n",
    "# Convert y_train_resampled to one-hot encoding\n",
    "y_train_resampled_categorical = to_categorical(y_train_resampled)\n",
    "\n",
    "# Reshape X_test for CNN\n",
    "X_test_array = X_test.values\n",
    "X_test_reshaped = X_test_array.reshape(X_test_array.shape[0], X_test_array.shape[1], 1)\n",
    "\n",
    "# Convert y_test to one-hot encoding\n",
    "y_test_categorical = to_categorical(y_test)\n",
    "\n",
    "# # Define CNN model\n",
    "# def build_cnn_model(input_shape):\n",
    "#     model = Sequential([\n",
    "#         Conv1D(filters=256, kernel_size=5, activation='relu', padding='same', input_shape=input_shape),\n",
    "#         BatchNormalization(),\n",
    "#         Dropout(0.3),\n",
    "        \n",
    "#         Conv1D(filters=256, kernel_size=5, activation='relu', padding='same'),\n",
    "#         BatchNormalization(),\n",
    "#         MaxPooling1D(pool_size=2),\n",
    "#         Dropout(0.5),\n",
    "        \n",
    "#         Flatten(),\n",
    "#         Dense(256, activation='relu'),\n",
    "#         Dropout(0.5),\n",
    "#         Dense(128, activation='relu'),\n",
    "#         Dropout(0.5),\n",
    "#         Dense(2, activation='softmax')  # Adjust for the number of classes\n",
    "#     ])\n",
    "#     model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# Define input shape\n",
    "input_shape_cnn = (X_train_resampled.shape[1], 1)\n",
    "cnn_model_smote = build_cnn_model(input_shape_cnn)\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# Train the model\n",
    "history_cnn_smote = cnn_model_smote.fit(\n",
    "    X_train_resampled,  # Reshaped training data\n",
    "    y_train_resampled_categorical,  # One-hot encoded labels\n",
    "    epochs=50,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping],\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9c0e4727-8a42-4090-a017-e066ddf06e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 6ms/step\n",
      "Confusion Matrix with SMOTE Oversampling:\n",
      " [[1459  134]\n",
      " [ 174  233]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC-ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN with SMOTE Oversampling</td>\n",
       "      <td>0.572482</td>\n",
       "      <td>0.634877</td>\n",
       "      <td>0.602067</td>\n",
       "      <td>0.58396</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.85269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model    Recall  Precision  F1 Score  F2 Score  \\\n",
       "0  CNN with SMOTE Oversampling  0.572482   0.634877  0.602067   0.58396   \n",
       "\n",
       "   Accuracy  AUC-ROC  \n",
       "0     0.846  0.85269  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "cnn_predictions_smote = cnn_model_smote.predict(X_test_reshaped)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "cnn_pred_labels_smote = np.argmax(cnn_predictions_smote, axis=1)\n",
    "\n",
    "# Calculate performance metrics\n",
    "cm_smote = confusion_matrix(y_test, cnn_pred_labels_smote)\n",
    "cnn_recall_smote = recall_score(y_test, cnn_pred_labels_smote)\n",
    "cnn_precision_smote = precision_score(y_test, cnn_pred_labels_smote)\n",
    "cnn_f1_smote = f1_score(y_test, cnn_pred_labels_smote)\n",
    "cnn_f2_smote = fbeta_score(y_test, cnn_pred_labels_smote, beta=2)\n",
    "cnn_accuracy_smote = accuracy_score(y_test, cnn_pred_labels_smote)\n",
    "cnn_roc_auc_smote = roc_auc_score(y_test, cnn_predictions_smote[:, 1])\n",
    "\n",
    "# Print Confusion Matrix\n",
    "print(\"Confusion Matrix with SMOTE Oversampling:\\n\", cm_smote)\n",
    "\n",
    "# Create a DataFrame to store the scores\n",
    "cnn_score_smote = pd.DataFrame(\n",
    "    data=[(cnn_recall_smote, cnn_precision_smote, cnn_f1_smote, cnn_f2_smote, cnn_accuracy_smote,cnn_roc_auc_smote)],\n",
    "    columns=['Recall', 'Precision', 'F1 Score', 'F2 Score', 'Accuracy', 'AUC-ROC']\n",
    ")\n",
    "cnn_score_smote.insert(0, 'Model', 'CNN with SMOTE Oversampling')\n",
    "\n",
    "# Display the DataFrame\n",
    "cnn_score_smote\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfec0d0-163f-4ba7-9f19-264329e1e4be",
   "metadata": {},
   "source": [
    "## SMOTE+TOMEK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ea2e8721-5ecb-46a0-a52c-27c8006c901a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "316/316 [==============================] - 5s 12ms/step - loss: 0.7152 - accuracy: 0.6985 - val_loss: 0.1327 - val_accuracy: 0.9643\n",
      "Epoch 2/50\n",
      "316/316 [==============================] - 3s 9ms/step - loss: 0.5100 - accuracy: 0.7552 - val_loss: 0.5761 - val_accuracy: 0.6709\n",
      "Epoch 3/50\n",
      "316/316 [==============================] - 4s 13ms/step - loss: 0.4807 - accuracy: 0.7725 - val_loss: 0.5305 - val_accuracy: 0.7010\n",
      "Epoch 4/50\n",
      "316/316 [==============================] - 2s 7ms/step - loss: 0.4719 - accuracy: 0.7845 - val_loss: 0.5145 - val_accuracy: 0.7181\n",
      "Epoch 5/50\n",
      "316/316 [==============================] - 4s 11ms/step - loss: 0.4617 - accuracy: 0.7854 - val_loss: 0.5382 - val_accuracy: 0.7026\n",
      "Epoch 6/50\n",
      "316/316 [==============================] - 4s 12ms/step - loss: 0.4545 - accuracy: 0.7915 - val_loss: 0.5218 - val_accuracy: 0.7070\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score, fbeta_score, accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming X_train and y_train are your original training features and labels\n",
    "X_train_array = X_train.values  # Convert X_train to numpy array if it's a DataFrame\n",
    "y_train_array = y_train.values  # Convert y_train to numpy array if it's a Series\n",
    "\n",
    "# Apply SMOTE + Tomek Links\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote_tomek.fit_resample(X_train_array, y_train_array)\n",
    "\n",
    "# Reshape X_train_resampled for CNN\n",
    "X_train_resampled = X_train_resampled.reshape(X_train_resampled.shape[0], X_train_resampled.shape[1], 1)\n",
    "\n",
    "# Convert y_train_resampled to one-hot encoding\n",
    "y_train_resampled_categorical = to_categorical(y_train_resampled)\n",
    "\n",
    "# Reshape X_test for CNN\n",
    "X_test_array = X_test.values  # Convert X_test to numpy array if it's a DataFrame\n",
    "X_test_reshaped = X_test_array.reshape(X_test_array.shape[0], X_test_array.shape[1], 1)\n",
    "\n",
    "# Convert y_test to one-hot encoding\n",
    "y_test_categorical = to_categorical(y_test)\n",
    "\n",
    "# # Define CNN model\n",
    "# def build_cnn(input_shape):\n",
    "#     model = Sequential([\n",
    "#         Conv1D(filters=256, kernel_size=5, activation='relu', padding='same', input_shape=input_shape),\n",
    "#         BatchNormalization(),\n",
    "#         Dropout(0.3),\n",
    "        \n",
    "#         Conv1D(filters=256, kernel_size=5, activation='relu', padding='same'),\n",
    "#         BatchNormalization(),\n",
    "#         MaxPooling1D(pool_size=2),\n",
    "#         Dropout(0.5),\n",
    "        \n",
    "#         Flatten(),\n",
    "#         Dense(256, activation='relu'),\n",
    "#         Dropout(0.5),\n",
    "#         Dense(128, activation='relu'),\n",
    "#         Dropout(0.5),\n",
    "#         Dense(2, activation='softmax')  # For binary classification\n",
    "#     ])\n",
    "#     model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# Build the CNN model\n",
    "cnn_model_smote_tomek = build_cnn((X_train_resampled.shape[1], 1))\n",
    "\n",
    "# Train the model\n",
    "history_cnn_smote_tomek = cnn_model_smote_tomek.fit(\n",
    "    X_train_resampled, y_train_resampled_categorical,\n",
    "    epochs=50,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f43d4a68-95e7-4e97-93e6-2b214e208881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step\n",
      "Confusion Matrix with SMOTE + Tomek Links:\n",
      " [[1390  203]\n",
      " [ 137  270]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC-ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN with SMOTE + Tomek Links</td>\n",
       "      <td>0.663391</td>\n",
       "      <td>0.570825</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.642551</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.850564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model    Recall  Precision  F1 Score  F2 Score  \\\n",
       "0  CNN with SMOTE + Tomek Links  0.663391   0.570825  0.613636  0.642551   \n",
       "\n",
       "   Accuracy   AUC-ROC  \n",
       "0      0.83  0.850564  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "cnn_predictions_smote_tomek = cnn_model_smote_tomek.predict(X_test_reshaped)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "cnn_pred_labels_smote_tomek = np.argmax(cnn_predictions_smote_tomek, axis=1)\n",
    "\n",
    "# Calculate performance metrics\n",
    "cnn_recall_smote_tomek = recall_score(y_test, cnn_pred_labels_smote_tomek)\n",
    "cnn_precision_smote_tomek = precision_score(y_test, cnn_pred_labels_smote_tomek)\n",
    "cnn_f1_smote_tomek = f1_score(y_test, cnn_pred_labels_smote_tomek)\n",
    "cnn_f2_smote_tomek = fbeta_score(y_test, cnn_pred_labels_smote_tomek, beta=2)\n",
    "cnn_accuracy_smote_tomek = accuracy_score(y_test, cnn_pred_labels_smote_tomek)\n",
    "cnn_roc_auc_smote_tomek = roc_auc_score(y_test, cnn_predictions_smote_tomek[:, 1])\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_smote_tomek = confusion_matrix(y_test, cnn_pred_labels_smote_tomek)\n",
    "\n",
    "# Print Confusion Matrix\n",
    "print(\"Confusion Matrix with SMOTE + Tomek Links:\\n\", cm_smote_tomek)\n",
    "\n",
    "# Create a DataFrame to store the scores\n",
    "metrics_smote_tomek = [(cnn_recall_smote_tomek, cnn_precision_smote_tomek, cnn_f1_smote_tomek, cnn_f2_smote_tomek, cnn_accuracy_smote_tomek,cnn_roc_auc_smote_tomek)]\n",
    "\n",
    "cnn_score_smote_tomek = pd.DataFrame(\n",
    "    data=metrics_smote_tomek, \n",
    "    columns=['Recall', 'Precision', 'F1 Score', 'F2 Score', 'Accuracy', 'AUC-ROC']\n",
    ")\n",
    "cnn_score_smote_tomek.insert(0, 'Model', 'CNN with SMOTE + Tomek Links')\n",
    "\n",
    "# Display the DataFrame\n",
    "cnn_score_smote_tomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0755b210-6197-488a-89fb-c7314e0aa87d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa37a54b-beff-4b56-af41-18383d15b448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6282b102-7bac-4ea4-8d95-4ff7e5c23498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92544546-0f9e-41d4-8038-f16e361dcb30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd742a12-6905-45d1-abe8-8818989153ef",
   "metadata": {},
   "source": [
    "## SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "719b79b0-2ffd-4aba-8ce6-aad019147ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "246/246 [==============================] - 5s 8ms/step - loss: 0.6566 - accuracy: 0.7595 - val_loss: 0.0896 - val_accuracy: 0.9760\n",
      "Epoch 2/50\n",
      "246/246 [==============================] - 3s 13ms/step - loss: 0.3951 - accuracy: 0.8289 - val_loss: 0.3111 - val_accuracy: 0.8751\n",
      "Epoch 3/50\n",
      "246/246 [==============================] - 3s 13ms/step - loss: 0.3525 - accuracy: 0.8502 - val_loss: 0.3121 - val_accuracy: 0.8664\n",
      "Epoch 4/50\n",
      "246/246 [==============================] - 4s 15ms/step - loss: 0.3303 - accuracy: 0.8589 - val_loss: 0.2594 - val_accuracy: 0.8832\n",
      "Epoch 5/50\n",
      "246/246 [==============================] - 2s 7ms/step - loss: 0.3212 - accuracy: 0.8622 - val_loss: 0.2440 - val_accuracy: 0.8904\n",
      "Epoch 6/50\n",
      "246/246 [==============================] - 2s 10ms/step - loss: 0.3083 - accuracy: 0.8680 - val_loss: 0.2480 - val_accuracy: 0.8863\n",
      "63/63 [==============================] - 1s 5ms/step\n",
      "Confusion Matrix with SMOTEENN:\n",
      " [[1207  386]\n",
      " [  93  314]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC-ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN with SMOTEENN</td>\n",
       "      <td>0.771499</td>\n",
       "      <td>0.448571</td>\n",
       "      <td>0.567299</td>\n",
       "      <td>0.674399</td>\n",
       "      <td>0.7605</td>\n",
       "      <td>0.852296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model    Recall  Precision  F1 Score  F2 Score  Accuracy  \\\n",
       "0  CNN with SMOTEENN  0.771499   0.448571  0.567299  0.674399    0.7605   \n",
       "\n",
       "    AUC-ROC  \n",
       "0  0.852296  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score, fbeta_score, accuracy_score, roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming X_train and y_train are your original training features and labels\n",
    "X_train_array = X_train.values  # Convert X_train to numpy array if it's a DataFrame\n",
    "y_train_array = y_train.values  # Convert y_train to numpy array if it's a Series\n",
    "\n",
    "# Apply SMOTEENN\n",
    "smoteenn = SMOTEENN(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smoteenn.fit_resample(X_train_array, y_train_array)\n",
    "\n",
    "# Reshape X_train_resampled for CNN\n",
    "X_train_resampled = X_train_resampled.reshape(X_train_resampled.shape[0], X_train_resampled.shape[1], 1)\n",
    "\n",
    "# Convert y_train_resampled to one-hot encoding\n",
    "y_train_resampled_categorical = to_categorical(y_train_resampled)\n",
    "\n",
    "# Reshape X_test for CNN\n",
    "X_test_array = X_test.values  # Convert X_test to numpy array if it's a DataFrame\n",
    "X_test_reshaped = X_test_array.reshape(X_test_array.shape[0], X_test_array.shape[1], 1)\n",
    "\n",
    "# Convert y_test to one-hot encoding\n",
    "y_test_categorical = to_categorical(y_test)\n",
    "\n",
    "# # Define CNN model\n",
    "# def build_cnn(input_shape):\n",
    "#     model = Sequential([\n",
    "#         Conv1D(filters=256, kernel_size=5, activation='relu', padding='same', input_shape=input_shape),\n",
    "#         BatchNormalization(),\n",
    "#         Dropout(0.3),\n",
    "        \n",
    "#         Conv1D(filters=256, kernel_size=5, activation='relu', padding='same'),\n",
    "#         BatchNormalization(),\n",
    "#         MaxPooling1D(pool_size=2),\n",
    "#         Dropout(0.5),\n",
    "        \n",
    "#         Flatten(),\n",
    "#         Dense(256, activation='relu'),\n",
    "#         Dropout(0.5),\n",
    "#         Dense(128, activation='relu'),\n",
    "#         Dropout(0.5),\n",
    "#         Dense(2, activation='softmax')  # For binary classification\n",
    "#     ])\n",
    "#     model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# Build the CNN model\n",
    "cnn_model_smoteenn = build_cnn((X_train_resampled.shape[1], 1))\n",
    "\n",
    "# Train the model\n",
    "history_cnn_smoteenn = cnn_model_smoteenn.fit(\n",
    "    X_train_resampled, y_train_resampled_categorical,\n",
    "    epochs=50,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Make predictions\n",
    "cnn_predictions_smoteenn = cnn_model_smoteenn.predict(X_test_reshaped)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "cnn_pred_labels_smoteenn = np.argmax(cnn_predictions_smoteenn, axis=1)\n",
    "\n",
    "# Calculate performance metrics\n",
    "cnn_recall_smoteenn = recall_score(y_test, cnn_pred_labels_smoteenn)\n",
    "cnn_precision_smoteenn = precision_score(y_test, cnn_pred_labels_smoteenn)\n",
    "cnn_f1_smoteenn = f1_score(y_test, cnn_pred_labels_smoteenn)\n",
    "cnn_f2_smoteenn = fbeta_score(y_test, cnn_pred_labels_smoteenn, beta=2)\n",
    "cnn_accuracy_smoteenn = accuracy_score(y_test, cnn_pred_labels_smoteenn)\n",
    "cnn_roc_auc_smoteenn = roc_auc_score(y_test, cnn_predictions_smoteenn[:, 1])\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_smoteenn = confusion_matrix(y_test, cnn_pred_labels_smoteenn)\n",
    "\n",
    "# Print Confusion Matrix\n",
    "print(\"Confusion Matrix with SMOTEENN:\\n\", cm_smoteenn)\n",
    "\n",
    "# Create a DataFrame to store the scores\n",
    "metrics_smoteenn = [(cnn_recall_smoteenn, cnn_precision_smoteenn, cnn_f1_smoteenn, cnn_f2_smoteenn, cnn_accuracy_smoteenn, cnn_roc_auc_smoteenn)]\n",
    "\n",
    "cnn_score_smoteenn = pd.DataFrame(\n",
    "    data=metrics_smoteenn, \n",
    "    columns=['Recall', 'Precision', 'F1 Score', 'F2 Score', 'Accuracy', 'AUC-ROC']\n",
    ")\n",
    "cnn_score_smoteenn.insert(0, 'Model', 'CNN with SMOTEENN')\n",
    "\n",
    "# Display the DataFrame\n",
    "cnn_score_smoteenn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da34904a-5889-4058-9b62-6751461baa6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb0c661-be39-4632-be33-43dbf5185b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf871db-fa6e-4195-b4c5-eae62e6f2edd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6863d2f0-9329-4dd1-9de5-36f7b9620744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77426810-6eab-46e4-a182-5834ec89e2da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a44a0e5-ad47-4e64-8090-8926a9132aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67079835-6bc3-4f29-8dc1-8bf0aa7954bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9d7716-b875-440c-979a-d5f919a159c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ff221c-6faa-4672-b671-73511e1f9700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc39614d-c996-4695-917e-992dbe7afdd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8672e0b8-7c18-4662-9805-52f1cd24a7b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b44f32-83ac-4d93-aa65-5605250a11c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301070d4-5753-4ae9-9bb4-f743ca6f601b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c048f5f-3f7b-44e2-9d05-d24f2758718e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f64688b-9786-4711-8df9-2f8e16e5da2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c2d71f-2471-4b19-ab3b-f80a1e6dbb0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b601ae19-97ab-4944-9810-df258547c2ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d082c05f-4d72-41c4-bcf9-ef16b15f5a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC-ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CNN with SMOTEENN</td>\n",
       "      <td>0.771499</td>\n",
       "      <td>0.448571</td>\n",
       "      <td>0.567299</td>\n",
       "      <td>0.674399</td>\n",
       "      <td>0.7605</td>\n",
       "      <td>0.852296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CNN with SMOTE + Tomek Links</td>\n",
       "      <td>0.663391</td>\n",
       "      <td>0.570825</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.642551</td>\n",
       "      <td>0.8300</td>\n",
       "      <td>0.850564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNN with Class Weights</td>\n",
       "      <td>0.658477</td>\n",
       "      <td>0.561845</td>\n",
       "      <td>0.606335</td>\n",
       "      <td>0.636580</td>\n",
       "      <td>0.8260</td>\n",
       "      <td>0.850862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNN with Random Oversampling</td>\n",
       "      <td>0.656020</td>\n",
       "      <td>0.553942</td>\n",
       "      <td>0.600675</td>\n",
       "      <td>0.632701</td>\n",
       "      <td>0.8225</td>\n",
       "      <td>0.841277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNN with SMOTE Oversampling</td>\n",
       "      <td>0.572482</td>\n",
       "      <td>0.634877</td>\n",
       "      <td>0.602067</td>\n",
       "      <td>0.583960</td>\n",
       "      <td>0.8460</td>\n",
       "      <td>0.852690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN with no Under/Over Sampling</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0.763265</td>\n",
       "      <td>0.573620</td>\n",
       "      <td>0.499199</td>\n",
       "      <td>0.8610</td>\n",
       "      <td>0.849831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model    Recall  Precision  F1 Score  F2 Score  \\\n",
       "5                CNN with SMOTEENN  0.771499   0.448571  0.567299  0.674399   \n",
       "3     CNN with SMOTE + Tomek Links  0.663391   0.570825  0.613636  0.642551   \n",
       "4           CNN with Class Weights  0.658477   0.561845  0.606335  0.636580   \n",
       "1     CNN with Random Oversampling  0.656020   0.553942  0.600675  0.632701   \n",
       "2      CNN with SMOTE Oversampling  0.572482   0.634877  0.602067  0.583960   \n",
       "0  CNN with no Under/Over Sampling  0.459459   0.763265  0.573620  0.499199   \n",
       "\n",
       "   Accuracy   AUC-ROC  \n",
       "5    0.7605  0.852296  \n",
       "3    0.8300  0.850564  \n",
       "4    0.8260  0.850862  \n",
       "1    0.8225  0.841277  \n",
       "2    0.8460  0.852690  \n",
       "0    0.8610  0.849831  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.concat([cnn_score, cnn_score_ros, cnn_score_smote,cnn_score_smote_tomek, cnn_score_class_weights,cnn_score_smoteenn], ignore_index=True, sort=False)\n",
    "predictions.sort_values(by=['Recall'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0fcd72-2ee2-4b77-9620-8b3480a93b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ec17db-2a71-47e1-be64-50caceb2d282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae487924-b58f-44b2-8ee9-1d1f6273b789",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
