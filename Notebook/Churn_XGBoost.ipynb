{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3f2927d-15ce-4423-a939-4c004e8da032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          XGBoost with    Recall  Precision  F1 Score  F2 Score  Accuracy  \\\n",
      "0          No Sampling  0.562654   0.399651  0.467347  0.520218    0.7390   \n",
      "1  Random Oversampling  0.702703   0.321348  0.441018  0.567911    0.6375   \n",
      "2   SMOTE Oversampling  0.879607   0.264597  0.406818  0.600470    0.4780   \n",
      "3  SMOTE + Tomek Links  0.877150   0.264444  0.406375  0.599396    0.4785   \n",
      "4             SMOTEENN  0.872236   0.344995  0.494429  0.668047    0.6370   \n",
      "5        Class Weights  0.707617   0.336056  0.455696  0.579477    0.6560   \n",
      "\n",
      "    ROC-AUC  \n",
      "0  0.705269  \n",
      "1  0.714167  \n",
      "2  0.746690  \n",
      "3  0.748527  \n",
      "4  0.827034  \n",
      "5  0.721225  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, fbeta_score, accuracy_score, roc_auc_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "import xgboost as xgb\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load and prepare data\n",
    "customer_df = pd.read_csv('./Churn_Modelling.csv')\n",
    "customer_df = customer_df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "\n",
    "# Define features\n",
    "categorical_features = ['Geography', 'Gender']\n",
    "numeric_features = ['CreditScore', 'Age', 'Tenure', 'Balance',\n",
    "                    'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']\n",
    "\n",
    "# Split data\n",
    "X = customer_df.drop('Exited', axis=1)\n",
    "y = customer_df['Exited']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize numeric features\n",
    "def Standard_Scaler(df, col_names):\n",
    "    scaler = StandardScaler().fit(df[col_names])\n",
    "    df[col_names] = scaler.transform(df[col_names])\n",
    "    return df\n",
    "\n",
    "X_train = Standard_Scaler(X_train, numeric_features)\n",
    "X_test = Standard_Scaler(X_test, numeric_features)\n",
    "\n",
    "# One-hot encode categorical features\n",
    "def one_hot_encode(df, col_names):\n",
    "    df_encoded = pd.get_dummies(df, columns=col_names, drop_first=True, dtype='float64')\n",
    "    return df_encoded\n",
    "\n",
    "X_train = one_hot_encode(X_train, categorical_features)\n",
    "X_test = one_hot_encode(X_test, categorical_features)\n",
    "\n",
    "# Function to train and evaluate the model\n",
    "def evaluate_model(pipeline, X_train, y_train, X_test, y_test):\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Calculate metrics\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    f2 = fbeta_score(y_test, y_pred, beta=2)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    return recall, precision, f1, f2, accuracy, roc_auc\n",
    "\n",
    "# Define XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "# Evaluate models with different sampling techniques\n",
    "results = defaultdict(list)\n",
    "\n",
    "# No Sampling\n",
    "pipeline = make_pipeline(xgb_model)\n",
    "results['No Sampling'] = evaluate_model(pipeline, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Random Oversampling\n",
    "pipeline = make_pipeline(RandomOverSampler(random_state=42), xgb_model)\n",
    "results['Random Oversampling'] = evaluate_model(pipeline, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# SMOTE Oversampling\n",
    "pipeline = make_pipeline(SMOTE(random_state=42), xgb_model)\n",
    "results['SMOTE Oversampling'] = evaluate_model(pipeline, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# SMOTE + Tomek Links\n",
    "pipeline = make_pipeline(SMOTETomek(random_state=42), xgb_model)\n",
    "results['SMOTE + Tomek Links'] = evaluate_model(pipeline, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# SMOTEENN\n",
    "pipeline = make_pipeline(SMOTEENN(random_state=42), xgb_model)\n",
    "results['SMOTEENN'] = evaluate_model(pipeline, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Class Weights\n",
    "xgb_model_weighted = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss',\n",
    "                                       scale_pos_weight=y_train.value_counts()[0]/y_train.value_counts()[1],\n",
    "                                       random_state=42)\n",
    "pipeline = make_pipeline(xgb_model_weighted)\n",
    "results['Class Weights'] = evaluate_model(pipeline, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "columns = ['Recall', 'Precision', 'F1 Score', 'F2 Score', 'Accuracy', 'ROC-AUC']\n",
    "df_results = pd.DataFrame.from_dict(results, orient='index', columns=columns).reset_index()\n",
    "df_results.rename(columns={'index': 'XGBoost with'}, inplace=True)\n",
    "\n",
    "# Display the DataFrame with the results\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35d6c700-c58f-4188-a53c-86c32dc9903d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGBoost with</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Sampling</td>\n",
       "      <td>0.562654</td>\n",
       "      <td>0.399651</td>\n",
       "      <td>0.467347</td>\n",
       "      <td>0.520218</td>\n",
       "      <td>0.7390</td>\n",
       "      <td>0.705269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Oversampling</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.321348</td>\n",
       "      <td>0.441018</td>\n",
       "      <td>0.567911</td>\n",
       "      <td>0.6375</td>\n",
       "      <td>0.714167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE Oversampling</td>\n",
       "      <td>0.879607</td>\n",
       "      <td>0.264597</td>\n",
       "      <td>0.406818</td>\n",
       "      <td>0.600470</td>\n",
       "      <td>0.4780</td>\n",
       "      <td>0.746690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SMOTE + Tomek Links</td>\n",
       "      <td>0.877150</td>\n",
       "      <td>0.264444</td>\n",
       "      <td>0.406375</td>\n",
       "      <td>0.599396</td>\n",
       "      <td>0.4785</td>\n",
       "      <td>0.748527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>0.872236</td>\n",
       "      <td>0.344995</td>\n",
       "      <td>0.494429</td>\n",
       "      <td>0.668047</td>\n",
       "      <td>0.6370</td>\n",
       "      <td>0.827034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Class Weights</td>\n",
       "      <td>0.707617</td>\n",
       "      <td>0.336056</td>\n",
       "      <td>0.455696</td>\n",
       "      <td>0.579477</td>\n",
       "      <td>0.6560</td>\n",
       "      <td>0.721225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          XGBoost with    Recall  Precision  F1 Score  F2 Score  Accuracy  \\\n",
       "0          No Sampling  0.562654   0.399651  0.467347  0.520218    0.7390   \n",
       "1  Random Oversampling  0.702703   0.321348  0.441018  0.567911    0.6375   \n",
       "2   SMOTE Oversampling  0.879607   0.264597  0.406818  0.600470    0.4780   \n",
       "3  SMOTE + Tomek Links  0.877150   0.264444  0.406375  0.599396    0.4785   \n",
       "4             SMOTEENN  0.872236   0.344995  0.494429  0.668047    0.6370   \n",
       "5        Class Weights  0.707617   0.336056  0.455696  0.579477    0.6560   \n",
       "\n",
       "    ROC-AUC  \n",
       "0  0.705269  \n",
       "1  0.714167  \n",
       "2  0.746690  \n",
       "3  0.748527  \n",
       "4  0.827034  \n",
       "5  0.721225  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9641294d-61e4-4f5d-8db8-1d0245e5a518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2f3ebf2-5601-4db6-8eed-0fff4f313ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for each sampling technique:\n",
      "{'No Sampling': {'xgbclassifier__learning_rate': 0.1, 'xgbclassifier__max_depth': 3, 'xgbclassifier__n_estimators': 100, 'xgbclassifier__subsample': 0.8}, 'Random Oversampling': {'xgbclassifier__learning_rate': 0.1, 'xgbclassifier__max_depth': 3, 'xgbclassifier__n_estimators': 100, 'xgbclassifier__subsample': 0.7}, 'SMOTE Oversampling': {'xgbclassifier__learning_rate': 0.1, 'xgbclassifier__max_depth': 3, 'xgbclassifier__n_estimators': 200, 'xgbclassifier__subsample': 0.8}, 'SMOTE + Tomek Links': {'xgbclassifier__learning_rate': 0.1, 'xgbclassifier__max_depth': 3, 'xgbclassifier__n_estimators': 200, 'xgbclassifier__subsample': 0.8}, 'SMOTEENN': {'xgbclassifier__learning_rate': 0.1, 'xgbclassifier__max_depth': 3, 'xgbclassifier__n_estimators': 200, 'xgbclassifier__subsample': 0.7}, 'Class Weights': {'xgbclassifier__learning_rate': 0.1, 'xgbclassifier__max_depth': 3, 'xgbclassifier__n_estimators': 100, 'xgbclassifier__subsample': 1.0}}\n",
      "\n",
      "Evaluation Metrics:\n",
      "          XGBoost with    Recall  Precision  F1 Score  F2 Score  Accuracy  \\\n",
      "0          No Sampling  0.535627   0.441296  0.483907  0.513666    0.7675   \n",
      "1  Random Oversampling  0.810811   0.293333  0.430809  0.599346    0.5640   \n",
      "2   SMOTE Oversampling  0.891892   0.292742  0.440801  0.632845    0.5395   \n",
      "3  SMOTE + Tomek Links  0.874693   0.304014  0.451204  0.635941    0.5670   \n",
      "4             SMOTEENN  0.874693   0.342967  0.492734  0.667667    0.6335   \n",
      "5        Class Weights  0.823096   0.282700  0.420854  0.595450    0.5390   \n",
      "\n",
      "    ROC-AUC  \n",
      "0  0.736105  \n",
      "1  0.737041  \n",
      "2  0.787706  \n",
      "3  0.796771  \n",
      "4  0.843514  \n",
      "5  0.734095  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, fbeta_score, accuracy_score, roc_auc_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "import xgboost as xgb\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load and prepare data\n",
    "customer_df = pd.read_csv('./Churn_Modelling.csv')\n",
    "customer_df = customer_df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "\n",
    "# Define features\n",
    "categorical_features = ['Geography', 'Gender']\n",
    "numeric_features = ['CreditScore', 'Age', 'Tenure', 'Balance',\n",
    "                    'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']\n",
    "\n",
    "# Split data\n",
    "X = customer_df.drop('Exited', axis=1)\n",
    "y = customer_df['Exited']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize numeric features\n",
    "def Standard_Scaler(df, col_names):\n",
    "    scaler = StandardScaler().fit(df[col_names])\n",
    "    df[col_names] = scaler.transform(df[col_names])\n",
    "    return df\n",
    "\n",
    "X_train = Standard_Scaler(X_train, numeric_features)\n",
    "X_test = Standard_Scaler(X_test, numeric_features)\n",
    "\n",
    "# One-hot encode categorical features\n",
    "def one_hot_encode(df, col_names):\n",
    "    df_encoded = pd.get_dummies(df, columns=col_names, drop_first=True, dtype='float64')\n",
    "    return df_encoded\n",
    "\n",
    "X_train = one_hot_encode(X_train, categorical_features)\n",
    "X_test = one_hot_encode(X_test, categorical_features)\n",
    "\n",
    "# Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'xgbclassifier__n_estimators': [100, 200],\n",
    "    'xgbclassifier__max_depth': [3, 6, 9],\n",
    "    'xgbclassifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'xgbclassifier__subsample': [0.7, 0.8, 1.0],\n",
    "}\n",
    "\n",
    "# Define cross-validation strategy\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Function to train and evaluate the model with hyperparameter tuning\n",
    "def evaluate_model_with_tuning(pipeline, param_grid, X_train, y_train, X_test, y_test):\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Calculate metrics\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    f2 = fbeta_score(y_test, y_pred, beta=2)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    return recall, precision, f1, f2, accuracy, roc_auc, grid_search.best_params_\n",
    "\n",
    "# Evaluate models with different sampling techniques\n",
    "results = defaultdict(list)\n",
    "best_params = {}\n",
    "\n",
    "# No Sampling\n",
    "pipeline = make_pipeline(xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42))\n",
    "results['No Sampling'], best_params['No Sampling'] = evaluate_model_with_tuning(pipeline, param_grid, X_train, y_train, X_test, y_test)[:6], evaluate_model_with_tuning(pipeline, param_grid, X_train, y_train, X_test, y_test)[6]\n",
    "\n",
    "# Random Oversampling\n",
    "pipeline = make_pipeline(RandomOverSampler(random_state=42), xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42))\n",
    "results['Random Oversampling'], best_params['Random Oversampling'] = evaluate_model_with_tuning(pipeline, param_grid, X_train, y_train, X_test, y_test)[:6], evaluate_model_with_tuning(pipeline, param_grid, X_train, y_train, X_test, y_test)[6]\n",
    "\n",
    "# SMOTE Oversampling\n",
    "pipeline = make_pipeline(SMOTE(random_state=42), xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42))\n",
    "results['SMOTE Oversampling'], best_params['SMOTE Oversampling'] = evaluate_model_with_tuning(pipeline, param_grid, X_train, y_train, X_test, y_test)[:6], evaluate_model_with_tuning(pipeline, param_grid, X_train, y_train, X_test, y_test)[6]\n",
    "\n",
    "# SMOTE + Tomek Links\n",
    "pipeline = make_pipeline(SMOTETomek(random_state=42), xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42))\n",
    "results['SMOTE + Tomek Links'], best_params['SMOTE + Tomek Links'] = evaluate_model_with_tuning(pipeline, param_grid, X_train, y_train, X_test, y_test)[:6], evaluate_model_with_tuning(pipeline, param_grid, X_train, y_train, X_test, y_test)[6]\n",
    "\n",
    "# SMOTEENN\n",
    "pipeline = make_pipeline(SMOTEENN(random_state=42), xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42))\n",
    "results['SMOTEENN'], best_params['SMOTEENN'] = evaluate_model_with_tuning(pipeline, param_grid, X_train, y_train, X_test, y_test)[:6], evaluate_model_with_tuning(pipeline, param_grid, X_train, y_train, X_test, y_test)[6]\n",
    "\n",
    "# Class Weights\n",
    "xgb_model_weighted = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss',\n",
    "                                       scale_pos_weight=y_train.value_counts()[0]/y_train.value_counts()[1],\n",
    "                                       random_state=42)\n",
    "pipeline = make_pipeline(xgb_model_weighted)\n",
    "results['Class Weights'], best_params['Class Weights'] = evaluate_model_with_tuning(pipeline, param_grid, X_train, y_train, X_test, y_test)[:6], evaluate_model_with_tuning(pipeline, param_grid, X_train, y_train, X_test, y_test)[6]\n",
    "\n",
    "# Convert results to DataFrame\n",
    "columns = ['Recall', 'Precision', 'F1 Score', 'F2 Score', 'Accuracy', 'ROC-AUC']\n",
    "df_results = pd.DataFrame.from_dict(results, orient='index', columns=columns).reset_index()\n",
    "df_results.rename(columns={'index': 'XGBoost with'}, inplace=True)\n",
    "\n",
    "# Display the DataFrame with the results\n",
    "print(\"Best Parameters for each sampling technique:\")\n",
    "print(best_params)\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9511dbf7-528d-4f8b-88e4-bbded0073644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGBoost with</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Sampling</td>\n",
       "      <td>0.535627</td>\n",
       "      <td>0.441296</td>\n",
       "      <td>0.483907</td>\n",
       "      <td>0.513666</td>\n",
       "      <td>0.7675</td>\n",
       "      <td>0.736105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Oversampling</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.430809</td>\n",
       "      <td>0.599346</td>\n",
       "      <td>0.5640</td>\n",
       "      <td>0.737041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE Oversampling</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.292742</td>\n",
       "      <td>0.440801</td>\n",
       "      <td>0.632845</td>\n",
       "      <td>0.5395</td>\n",
       "      <td>0.787706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SMOTE + Tomek Links</td>\n",
       "      <td>0.874693</td>\n",
       "      <td>0.304014</td>\n",
       "      <td>0.451204</td>\n",
       "      <td>0.635941</td>\n",
       "      <td>0.5670</td>\n",
       "      <td>0.796771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>0.874693</td>\n",
       "      <td>0.342967</td>\n",
       "      <td>0.492734</td>\n",
       "      <td>0.667667</td>\n",
       "      <td>0.6335</td>\n",
       "      <td>0.843514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Class Weights</td>\n",
       "      <td>0.823096</td>\n",
       "      <td>0.282700</td>\n",
       "      <td>0.420854</td>\n",
       "      <td>0.595450</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.734095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          XGBoost with    Recall  Precision  F1 Score  F2 Score  Accuracy  \\\n",
       "0          No Sampling  0.535627   0.441296  0.483907  0.513666    0.7675   \n",
       "1  Random Oversampling  0.810811   0.293333  0.430809  0.599346    0.5640   \n",
       "2   SMOTE Oversampling  0.891892   0.292742  0.440801  0.632845    0.5395   \n",
       "3  SMOTE + Tomek Links  0.874693   0.304014  0.451204  0.635941    0.5670   \n",
       "4             SMOTEENN  0.874693   0.342967  0.492734  0.667667    0.6335   \n",
       "5        Class Weights  0.823096   0.282700  0.420854  0.595450    0.5390   \n",
       "\n",
       "    ROC-AUC  \n",
       "0  0.736105  \n",
       "1  0.737041  \n",
       "2  0.787706  \n",
       "3  0.796771  \n",
       "4  0.843514  \n",
       "5  0.734095  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deb789a-c049-4928-83d1-d84662ec0cee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d89f20-58fe-49d6-b8cf-0395517cee97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
